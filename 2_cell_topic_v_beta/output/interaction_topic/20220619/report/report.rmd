---
title: "SPRUCE - Single-cell Pairwise Relationships Untangled by Composite ETM"
author: "Sishir Subedi and Yongjin Park"
date: "`r format(Sys.time(), ' %X, %b %d, %Y')`"
fontsize: 11pt
output:
  pdf_document:
    latex_engine: xelatex
    citation_package: natbib
    fig_caption: true
bibliography: references.bib 
link-citations: yes
tables: yes
always_allow_html: true
header-includes:
 - \usepackage{fontspec}
 - \usepackage{booktabs}
 - \usepackage{longtable}
 - \usepackage{array}
 - \usepackage{multirow}
 - \usepackage{wrapfig}
 - \usepackage{float}
 - \usepackage{colortbl}
 - \usepackage{pdflscape}
 - \usepackage{tabu}
 - \usepackage{threeparttable}
 - \usepackage{threeparttablex}
 - \usepackage{makecell}
 - \usepackage{amsmath}
 - \usepackage{amssymb}
 - \usepackage{setspace}\doublespacing
---
# SUMMARY
# INTRODUCTION

# RESULTS

## The SPRUCE model
SPRUCE utilizes composite embedded topic models (ETM) to identify cell types and define its subtypes based on cell-cell communication in tumour microenvironment (TME). The input for the model is a single-cell data, which contains multiple cell types present in TME accross different data sets. Let ${X_{iG}}$ be raw count gene expression data for $G$ genes in cell $i$. We modeled ${X_{iG}}$ with multinomial distribution parameterized by a normalized gene expression frequency which achieves a scale-invariant property across different cells, batches, and data sets. Further, we introduce Dirichlet prior on the gene frequency and parameterize the Dirichlet as a generalized linear model(GLM) with linear combinations of topic specific probabilities.

The model consists of two ETMs each with a pair of encoder-decoder networks. The first ETM, cell topic model, takes gene expression single-cell data as input and models cell topic and topic specific gene probabilities. Next, we assigned a cell topic to each cell based on the highest topic proportion from the cell topic model. The topic assignment was used to construct a set of neighbours for each cell such that one cell is paired with five nearest neighbours from each topic. The ligand and receptor gene expression data from each cell pair were transformed to each other's space by interaction database celltalkdb. The transformed ligand and receptor data were treated as two independent modules with its own encoder and decoder in the model. The latent variables with encoded information from two modules were combined by taking its average to obtained a final interaction topic variables as mixture of experts from ligand and recetor latent space. The second ETM, interaction topic model, uses transformed ligand-receptor data from neighbouring cell pairs as input and models combined interaction topic for each cell pair and separate topic specifc ligand and receptor gene probabilities.


## SPRUCE identifies resident cell types and cancer subtypes

To assign each cell to a cell topic we applied our purposed cell-topic model to a mixture dataset from tumour microenvironment of breast cancer, which consisted 155913 cells and 20265 genes. After unsupervised training of the model, all cells were mapped in the latent cell topic space. Clustering on latent variables was performed using kmeans and clusters were mapped to known cell populations using majority rule. Annotations for cell type was assigned to each cell based on assignment from previous studies and in case of its unavailability we used reference-based cell type identification method SingleR with a tumor micro-environment reference dataset from CHETAH (add reference). The latent cell topics with assigned cell type were visualized with UMAP which shows distint clusters of all major types of cells including epithelial, immune, and cancer cells presnt in tumor microenvironment ( Figure 1a).  The estimated cell topic proportions show that the resident cell types have similar topic proportions. However, cancer cells have different mixture of topic proportions which shows that the model identified many distinct cell topics of cancer cells(Figure 1b). Furthermore, the model optimized the gene frequency for each topic which is biologically interpretable in understanding which genes are driving each cell topic (Figure 1c). Here, cell topics for different cancer cells show disjoint set of genes with high frequencies. 

## Cell-cell interaction topics generated by SPRUCE reveals new cancer types
The interaction topic model uses transformend ligand-receptor gene expression data from neighbouring cell pairs and models interaction topic for each cell pair and identifies ligand and receptor genes enriched in each interaction topic. The model identified seven major patterns of interaction topic for cell pairs with cancer cell (Figure 2a). Each interaction topic represent unique cell-cell interaction state based on the gene expression levels ligands and receptor genes between them. The cell type distribution of neighbouring cells of cancer cells in each topic show enrichment of specific cell types (Figure 2b). For example, topic 22 and 24 shows enrichment of immune cells where topic 22 has higher proportion of T-cells like neighbours while topic 24 has higher proportion of Monocyte/B-cells like neighbours. Similarly, topic 18 shows enrichment of cancer-associated fibroblasts and perivascular like cell types. The top ligand and receptor genes in each topic identified by the model corresponds with the cell types enriched in the respective topic. Similarly, these top ligand and receptor genes are highly expressed in cancer and non-cancer cell pairs. 


## Different interaction topics induce subtype-specific gene-gene networks 

## Each interaction topic show disjoint differential expression genes

## METHOD DETAILS

### Data origins and preprocessing
We generated a mixuture dataset combining three different recent breast cancer studies. The first one is a breast cancer dataset consisting of 100k cells from a single-cell atlas of human breast cancers (\cite{wu2021single}). The secod dataset consited of 48k cells from a single-cell atlas of the healthy breast tissues (\cite{bhat2021single}).The third dataset is 6k subset of breast cancer CD4 and CD8 T-cells from a pan-cancer atlas of tumour-infiltrating T cells profiled across 21 cancer types and 316 donors (\cite{zheng2021pan}). The total number of cells in the combined dataset was 155913. We filtered out genes detected in less than 3 cells along with mitochondrial gene and spike genes, which lead to 20265 genes in the final dataset. 


### Cell topic model
The cell topic modeling extends on the ideas of LDA. Consider a sample of cells ${i_{1},....,i_{N}}$ and a list of genes ${g_{1},....,g_{G}}$, where ${x_{i1},x_{i2},...,x_{iG}}$ are raw count data for $G$ genes in cell $i$. We assume that each cell count vector $X_{i}$ was generated from a multinomial distribution parameterized by a gene expression frequency matrix with an element $\rho_{ig}$ of a gene $g$ in the cell $i$.

$$p(\mathbf{x}_{i}|\rho_{i}) = \prod_{g} \rho_{ig}^{X_{ig}}$$

We introduce Dirichlet prior on the $\rho$ and parameterize the Dirichlet as a generalized linear model (GLM). Exploiting the conjugacy between the multinomial and Dirichlet, we integrate out the unknown parameters $\rho$.

$$p(\rho_{i}|\lambda_{i}) = \frac{\Gamma(\sum_{g} \lambda_{ig})}{\prod_{g} \Gamma(\lambda_{ig})} \prod_{g \in \textsf{genes}} \rho_{ig}^{\lambda_{ig} - 1}$$

$$\lambda_{ig} = \exp\left( \sum_{t=1}^{T} \theta_{it} ( \beta_{tg} + b_{g} ) \right)$$

The topic proportion $\theta_{it}$ for cell $i$ is drawn from logistic normal distribution with model hyperparameters $\delta_{it}$ and we assume topic proportions within a simplex, namely $\sum_{t\in \textsf{topics}} \theta_{it} = 1$.

\begin{equation}
\begin{split}
\delta_{it} \sim N(0,I);\theta_{it} = softmax(\delta_{it})\\
\end{split}
\end{equation}

The marginal likelihood 

$$p(\mathbf{x}_{i}| \cdot ) = 
\frac{\Gamma(\sum_{g} \lambda_{ig})} {\sum_{g} \Gamma(\lambda_{ig})} \frac{\Gamma(\sum_{g} \lambda_{ig} + X_{ig})}{\sum_{g} \Gamma(\lambda_{ig} + X_{ig})}$$


The marginal likelihood of each cell is an intractable problem because it involves integral over the topic proportion. Variational inference techniques can be used to approximate this type of intractable integrals. 

### Generating neighbour cells

A set of neighbour cells were calculated for each cell using the topic assignment from cell topic model. For each cell, five neighbours from each topic were calculated using python package \cite{ANNOY}. A annoy model was created for each topic with total cell count more than 100. In total, we generated 159 neighbour cell pairs for each cell - 32 topics and 5 neighbours from each topic, excluding self neighbour pair.

### Ligand receptor data augmentation

For each cell pair generated by neighbour analysis, we transformed ligand and receptors raw gene expression data into each others space using a binary interaction matrx generated from publicly available celltalkDB database (\cite{shao2021celltalkdb}).


### Interaction topic analysis


Multinomial-Dirichlet:


$$p(\mathbf{y}_{i}|\mathbf{q}_{i}) = \frac{(\sum_{g} Y_{ig})!}{\prod_{g} Y_{ig}!} \prod_{g} q_{ig}^{Y_{ig}}$$

$$\mathbf{q}_{i} \sim \textsf{Dir}(\mathbf{q}_{i}|\rho_{i}) = \frac{\Gamma(\sum_{g}\rho_{ig})}{\prod_{g} \Gamma(\rho_{ig})} \prod_{g} q_{ig}^{\rho_{ig} - 1}$$


Single-cell generative model:
$$p(\mathbf{x}_{j}| \cdot ) = 
\frac{\Gamma(\sum_{g} \lambda_{jg})} {\sum_{g} \Gamma(\lambda_{jg})} \frac{\Gamma(\sum_{g} \lambda_{jg} + X_{jg})}{\sum_{g} \Gamma(\lambda_{jg} + X_{jg})}$$

where

$$\lambda_{jg} =  \lambda_{0}  \exp\left( \sum_{t=1}^{T} \theta_{jt} ( \beta_{tg} + \delta_{g} ) \right)$$

$$\lambda_{0} = \exp(\tilde{\lambda}_{0})$$


$\sum_{t} \theta_{jt} = 1$ 

Bayesian regularization of the model parameters

$$\beta_{tg} \sim \mathcal{N}\!\left(0, 1\right)$$

Total Expected log-likelihood Lower-bound (ELBO):


\begin{align}
\frac{J}{n} 
    &= \frac{1}{n}\sum_{i=1}^{n} \log p(\mathbf{x}_{i}|\theta_{i}(\mathbf{z}_{i}), \beta) \\
	&  + \frac{1}{n}\sum_{i=1}^{n} \sum_{t=1}^{T} D_{\textsf{KL}}\left( q(z_{it}) \| p(z_{it}) \right) \\
	&  + \frac{1}{n}\sum_{t=1}^{T}\sum_{l=1}^{L} D_{\textsf{KL}}\left( q(\beta_{tl}) \| p(\beta_{tl}) \right) \\
	&  + \frac{1}{n}\sum_{t=1}^{T}\sum_{r=1}^{R} D_{\textsf{KL}}\left( q(\beta_{tr}) \| p(\beta_{tr}) \right) 
\end{align}


\newpage
# SUPPLEMENTAL

Let $p_{\theta}(z \mid x)$ be a true posterior and $q_{\phi}(z \mid x)$ be an approximate posterior.

\begin{equation}
\begin{split}
D_{KL}(q_{\phi}\mid\mid p_{\theta}) & = E_{q_{\phi}}[log  \frac {q_{\phi}(z \mid x)}{p_{\theta}(z \mid x)}]\\
& = E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] - E_{q_{\phi}} [log \ {p_{\theta}(z \mid x)}]\\
& = E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] - E_{q_{\phi}} [log \ \frac {p_{\theta}(z,x)}{p_{\theta}(x)}]\\
& = E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] - E_{q_{\phi}} [log \ {p_{\theta}(z,x)}] + E_{q_{\phi}} [log \ {p_{\theta}(x)}]\\
& = E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] - E_{q_{\phi}} [log \ {p_{\theta}(z,x)}] + \int q_{\phi}(z \mid x) log \ {p_{\theta}(x)}dz\\
& = E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] - E_{q_{\phi}} [log \ {p_{\theta}(z,x)}] + log \ {p_{\theta}(x)} \int q_{\phi}(z \mid x) dz \\
& = E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] - E_{q_{\phi}} [log \ {p_{\theta}(z,x)}] + log \ {p_{\theta}(x)}\\
log \ {p_{\theta}(x)} & = - E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] + E_{q_{\phi}} [log \ {p_{\theta}(z,x)}] + D_{KL}(q_{\phi}\mid\mid p_{\theta}) \\
\end{split}
\end{equation}

Here, $D_{KL}(q_{\phi}\mid\mid p_{\theta})$ is intractable but it is always $\geq$ 0, we can use this property to remove $D_{KL}$ from the equation and the marginal log likelihood $log \ {p_{\theta}(x)}$ will be at least $\geq - E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] + E_{q_{\phi}} [log \ {p_{\theta}(z,x)}]$. Since this term is the lower bound on the evidence,it is called as Evidence Lower Bound(ELBO). We maximize the marginal log likelihood by maximizing the ELBO and indirectly minimize the KL divergence.

\begin{equation}
\begin{split}
ELBO & = - E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] + E_{q_{\phi}} [log \ {p_{\theta}(z,x)}] \\
& = - E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] + E_{q_{\phi}} [log \ {p_{\theta}(x \mid z)}] + E_{q_{\phi}} [log \ {p_{\theta}(z)}] \\
& = E_{q_{\phi}} [log \ {p_{\theta}(x \mid z)}]  - E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] + E_{q_{\phi}}[log \ {p_{\theta}(z)}] \\
ELBO & = E_{q_{\phi}} [log \ {p_{\theta}(x \mid z)}]  - E_{q_{\phi}} [log \frac{q_{\phi}(z \mid x)}{p_{\theta}(z)}] \\
\end{split}
\end{equation}

Here, $E_{q_{\phi}} [log \ {p_{\theta}(x \mid z)}]$ is an expected reconstruction error and $E_{q_{\phi}} [log \frac{q_{\phi}(z \mid x)}{p_{\theta}(z)}]$ is KL Divergence between approximate posterior and the prior.


Approximate posterior and prior

The approximate posterior $q_{\phi}(z \mid x)$ is a Gaussian variational distribution $q(\delta_{i};i_{n},v)$ = $N(\mu,\Sigma)$ whose mean and variance are constructed form a neural network parameterized by $v$. The network takes raw count data of a cell 
$i_{n}$ for $G$ genes and outputs a mean and variance of $\delta_{i}$. The prior $p_{\theta}(z)$ = $N(0,I)$. The KL divergence between these two form of Gaussians exist in closed form and given as-

\begin{equation}
\begin{split}
D_{KL}(q_{\phi}\mid\mid p_{\theta}) & = E_{q_{\phi}} [log \frac{q_{\phi}(z \mid x)}{p_{\theta}(z)}] \\
& = E_{q_{\phi}}[log \ {q_{\phi}(z \mid x)}] - E_{q_{\phi}} [log \ {p_{\theta}(z)}]\\
& = 1/2 \sum_{d} (1 + log(\Sigma) - \mu^{2} - \Sigma) \\
\end{split}
\end{equation}

In addition to the latent state KL divergence, we take into account the uncertainty of $\beta_{tg}$ parameters:

$$\beta_{tg} \sim \mathcal{N}\!\left(0, 1\right)$$

Total Expected log-likelihood Lower-bound (ELBO):

\begin{align}
\frac{J}{n} 
    &=\frac{1}{n}\sum_{i=1}^{n} \log p(\mathbf{x}_{i}|\theta_{i}(\mathbf{z}_{i}), \beta) \\
	&  + \frac{1}{n}\sum_{i=1}^{n} \sum_{t=1}^{T} D_{\textsf{KL}}\left( q(z_{it}) \| p(z_{it}) \right) \\
	&  + \frac{1}{n}\sum_{t=1}^{T}\sum_{g=1}^{G} D_{\textsf{KL}}\left( q(\beta_{tg}) \| p(\beta_{tg}) \right) \\
\end{align}

\newpage


Total number of cells from different datasets-

```json
GSE164898            48495 

T-cells              35214 
Cancer Epithelial    24489 
Myeloid               9675 
Endothelial           7605 
CAFs                  6573 
PVL                   5423 
Normal Epithelial     4355 
Plasmablasts          3524 
B-cells               3206 --> 101149 

GSE156728-CD4         3063 
GSE156728-CD8         4291 --> 6269
```

